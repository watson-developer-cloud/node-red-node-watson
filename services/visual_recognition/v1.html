<!--
  Copyright 2015 IBM Corp. 

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<script type="text/x-red" data-template-name="watson-visual-recognition">
    <div id="credentials-check" class="form-row">
        <div class="form-tips">
            <i class="fa fa-question-circle"></i><b> Please wait: </b> Checking for bound service credentials...
        </div>
    </div>
    <div class="form-row">
        <label for="node-input-name"><i class="fa fa-tag"></i> Name</label>
        <input type="text" id="node-input-name" placeholder="Name">
    </div>
    <div class="form-row credentials" style="display: none;">
        <label for="node-input-username"><i class="fa fa-user"></i> Username</label>
        <input type="text" id="node-input-username" placeholder="Username">
    </div>
    <div class="form-row credentials" style="display: none;">
        <label for="node-input-password"><i class="fa fa-key"></i> Password</label>
        <input type="password" id="node-input-password" placeholder="Password">
    </div>
</script>

<script type="text/x-red" data-help-name="watson-visual-recognition">
    <p><b>NB:</b> This node uses the old beta API and it is only being retained for backward compatibility for 
        anyone that has an Visual Recognition credentials. 
        It will no longer work with new Visual Recognition keys.</p>
    <br/>
    <p>The Visual Recognition service analyses images to understand their contents.</p>
    <p>The image to be analysed should be passed in on <code>msg.payload</code>.</p>
    <p>Supported <code>msg.payload</code> types:</b>.</p>
    <ul>
        <li><b>String</b> URL to image</li>
        <li><b>Buffer</b> Raw Image Bytes</li>
    </ul>
    <p>The identified images labels will be returned on <code>msg.labels</code>.</p>
    <p>For more information about the Visual Recognition service, read the <a href="https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/visual-recognition.html">documentation</a>.</p>
</script>

<script type="text/javascript">
    (function() {
        RED.nodes.registerType('watson-visual-recognition', {
            category: 'Watson Deprecated',
            defaults: {
                name: {value: ""},
            },
            credentials: {
              username: {type:"text"},
              password: {type:"password"}
            },
            color: "rgb(32, 178, 239)",
            inputs: 1,
            outputs: 1,
            icon: "visual_recognition.png",
            paletteLabel: "visual recognition",
            label: function() {
                return this.name || "visual recognition";
            },
            labelStyle: function() {
                return this.name ? "node_label_italic" : "";
            },
            oneditprepare: function() {
                $.getJSON('watson-visual-recognition/vcap/')
                  .done(function (service) {
                    $('.credentials').toggle(!service);
                  })
                  .fail(function () {
                    $('.credentials').show();
                  }).always(function () {
                    $('#credentials-check').hide();
                  })
            }
        });
    })();
</script>

<script type="text/javascript">

	function classifiersList(node) {
		
		console.log("-> classifiersList");
		
		var last = $('#node-input-classifier').children().last();
		var opts = [];
		$.getJSON('watson-visual-recognition/list/'+node.service,function(data) {
			var classifiers = data.classifiers;
			for (var i=0; i < classifiers.length; i++) {
				console.log("-> classifiersList.data "+classifiers[i].name);
				var selected = node.classifier === classifiers[i].name;
				opts.push(
					'<option value="' + classifiers[i].classifier_id + '"' + (selected ? " selected":"") + '>' +
						classifiers[i].name +
					'</option>'
				);
			}

			console.log("-> node.classifier: "+node.classifier);
			if (opts.length === 0) {
				$('#node-input-classifier').find("option").filter(function() {
					return $(this).val() === node.classifier;
				}).attr('selected', true);
			} else {
				last.before(opts.join(""));
			}
		});
	}

	RED.nodes.registerType('watson-visual-util',{
		category: 'Watson Deprecated',
		color: '#FFFF80',
		defaults: {
			name: {value:""},
			command: {value:"",required:true},
			classifier: {value:"",required:false},
			username: {value:"",required:true},
			password: {value:"",required:true},
			service: {value:"",required:true}
		},		
		inputs:1,
		outputs:1,
		icon: "visual2.png",
		label: function() {
			return this.name||"visual utils";
		},
		
		visuals: [],
		
		oneditprepare: function() {
			var node = this;
			console.log("this: "+JSON.stringify(this));
			
			classifiersList(node);
	
			$.getJSON('watson-visual-recognition/vcap/',function(data) {
				
				node.visuals = data;
				var last = $('#node-input-service').children().last();
				var opts = [];
	
				for (var i=0; i < data.length; i++) {
					var selected = node.service === data[i].name;
					opts.push(
						'<option value="' + data[i].name + '"' + (selected ? " selected":"") + '>' +
							data[i].name +
						'</option>'
					);
				}
	
				if (opts.length === 0) {
					node.service = "_ext_";
					$('#node-input-service').find("option").filter(function() {
						return $(this).val() === node.service;
					}).attr('selected', true);
				} else {
					last.before(opts.join(""));
				}
	
				if (node.service === '_ext_') {
					$("#external_visual_service :input").attr('disabled',false);
				} else {
					for (var i2=0;i2<node.visuals.length;i2++) {
						var ws = node.visuals[i2];
						if (ws.name === node.service) {
							$("#node-input-username").val(ws.username);
							$("#node-input-password").val(ws.password);
							console.log("** Visual: "+JSON.stringify(node.visuals[i2]));
						}
					}
					$("#external_visual_service :input").attr('disabled',true);
				}
				
				if (node.command === 'list') {
					$("#node-input-classifier :input").attr('disabled',true);
				} else {
					$("#node-input-classifier :input").attr('disabled',false);
				}

			});

			$("#node-input-command").on("change",function() {
				if (this.value === 'list') {
					$("#node-input-classifier :input").attr('disabled',true);
				} else {
					$("#node-input-classifier :input").attr('disabled',false);
				}
			});

			$("#node-input-service").on("change",function() {
				$("#node--input-service").val(this.value);
				if (this.value === '_ext_') {
					$("#external_visual_details :input").attr('disabled',false);
				} else {
					if(node.visuals) {
						$("#external_visual_details :input").attr('disabled',true);
						for (var i=0;i<node.visuals.length;i++) {
							var ws = node.visuals[i];
							if (ws.name === this.value) {
								$("#node-input-username").val(ws.username);
								$("#node-input-password").val(ws.password);
							}
						}
					}

				}
			});

			$("#node-input-command").on("change",function() {
				if (this.value === 'list') {
					$("#node-input-classifier :input").attr('disabled',true);
				} else {
					$("#node-input-classifier :input").attr('disabled',false);
				}
			});
		}

	});

	RED.nodes.registerType('watson-visual-training',{
		category: 'Watson Deprecated',
		color: '#FFFF80',
		defaults: {
			name: {value:""},
			classifier: {value:"",required:true},
			username: {value:"",required:true},
			password: {value:"",required:true},
			service: {value:"",required:true}
		},		
		inputs:1,
		outputs:1,
		icon: "visual2.png",
		label: function() {
			return this.name||"visual training";
		},
		
		visuals: [],

		oneditprepare: function() {
			var node = this;
			console.log("this: "+JSON.stringify(this));
	
			$.getJSON('watson-visual-recognition/vcap/',function(data) {
				
				node.visuals = data;
				console.log("Visuals: "+JSON.stringify(data));
				
				var last = $('#node-input-service').children().last();
				var opts = [];
	
				console.log("node.service: "+node.service);
				for (var i=0; i < data.length; i++) {
					console.log("data.name: "+data[i].name);
					
					var selected = node.service === data[i].name;
					console.log("selected: "+selected);
					opts.push(
						'<option value="' + data[i].name + '"' + (selected ? " selected":"") + '>' +
							data[i].name +
						'</option>'
					);
				}
	
				if (opts.length === 0) {
					node.service = "_ext_";
					$('#node-input-service').find("option").filter(function() {
						return $(this).val() === node.service;
					}).attr('selected', true);
				} else {
					last.before(opts.join(""));
				}
	
				if (node.service === '_ext_') {
				} else {
					for (var i2=0;i2<node.visuals.length;i2++) {
						var ws = node.visuals[i2];
						if (ws.name === node.service) {
							$("#node-input-username").val(ws.username);
							$("#node-input-password").val(ws.password);
							util.log("** Visual: "+JSON.stringify(node.visuals[i2]));
						}
					}
					$("#external_visual_details :input").attr('disabled',true);
				}
			});

			$("#node-input-service").on("change",function() {
				$("#node--input-service").val(this.value);
				if (this.value === '_ext_') {
					$("#external_visual_details :input").attr('disabled',false);
				} else {
					if(node.visuals) {
						$("#external_visual_details :input").attr('disabled',true);
						for (var i=0;i<node.visuals.length;i++) {
							var ws = node.visuals[i];
							if (ws.name === this.value) {
								$("#node-input-username").val(ws.username);
								$("#node-input-password").val(ws.password);
							}
						}
					}

				}
			});
		}
	});

</script>

<script type="text/x-red" data-template-name="watson-visual-util">
	<div class="form-row">
		<label for="node-input-name"><i class="icon-tag"></i> Name</label>
		<input type="text" id="node-input-name" placeholder="Name">
	</div>
	<div class="form-row">
		<label for="node-input-command"><i class="icon-tag"></i> Command</label>
		<select id="node-input-command">
			<option value="list">List Classifiers</option>
			<option value="details">Classifier Details</option>
			<option value="delete">Delete Classifier</option>
		</select>
	</div>
	<div class="form-row">
		<label for="node-input-classifier"><i class="icon-tag"></i> Classifier</label>
		<select id="node-input-classifier">
			<option value="" disabled></option>
		</select>
		<!--input type="text" id="node-input-classifier" placeholder="Name"-->
	</div>
	<div class="form-row">
		<label for="node-input-service"><i class="fa fa-globe"></i> Service</label>
		<select id="node-input-service">
			<option value="" disabled></option>
			<option value="_ext_"> External service</option>
		</select>
	</div>
	<div id="external_visual_details">
		<div class="form-row">
			<label for="node-input-username"><i class="fa fa-user"></i> Username</label>
			<input type="text" id="node-input-username">
		</div>
		<div class="form-row">
			<label for="node-input-password"><i class="fa fa-lock"></i> Password</label>
			<input type="text" id="node-input-password">
		</div>
	</div>
</script>

<script type="text/x-red" data-help-name="watson-visual-util">
    <p><b>NB:</b> This node uses the old beta API and it is only being retained for backward compatibility for 
        anyone that has an Visual Recognition credentials. 
        It will no longer work with new Visual Recognition keys.</p>
    <br/>
    <p>A node for managing the classifiers in the Visual Recognition service in Watson</p>
	<p>More information about this service can be found in the 
	<a href='https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/doc/visual-recognition/'>Image Recognition API documentation</a></p>.
</script>

<script type="text/x-red" data-template-name="watson-visual-training">
	<div class="form-row">
		<label for="node-input-name"><i class="icon-tag"></i> Name</label>
		<input type="text" id="node-input-name" placeholder="Name">
	</div>
	<div class="form-row">
		<label for="node-input-classifier"><i class="icon-tag"></i> Classifier</label>
		<input type="text" id="node-input-classifier" placeholder="Name">
	</div>
	<div class="form-row">
		<label for="node-input-service"><i class="fa fa-globe"></i> Service</label>
		<select id="node-input-service">
			<option value="" disabled></option>
			<option value="_ext_"> External service</option>
		</select>
	</div>
	<div id="external_visual_details">
		<div class="form-row">
			<label for="node-input-username"><i class="fa fa-user"></i> Username</label>
			<input type="text" id="node-input-username">
		</div>
		<div class="form-row">
			<label for="node-input-password"><i class="fa fa-lock"></i> Password</label>
			<input type="text" id="node-input-password">
		</div>
	</div>
</script>

<script type="text/x-red" data-help-name="watson-visual-training">
    <p><b>NB:</b> This node uses the old beta API and it is only being retained for backward compatibility for 
        anyone that has an Visual Recognition credentials. 
        It will no longer work with new Visual Recognition keys.</p>
    <br/>
	<p>A node for training the Visual Recognition service in Watson</p>
	<p>This service requires that two sets of images are provided for the training. These sets of files should be 
	zipped and provided to the node either as binary streams or as URL's. The positive and negative set of images 
	should be pointed by <b>msg.positive</b> and <b>msg.negative</b>.</p>
	<p>More information about this service can be found in the 
	<a href='https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/doc/visual-recognition/'>Image Recognition API documentation</a></p>.
</script>


